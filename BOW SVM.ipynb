{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import urduhack\n",
    "import re\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "urdu_doc = pd.read_csv('C:/Users/EMAAZ/Desktop/Dataset/UrduReview.csv' , encoding ='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urdu_doc = urdu_doc.dropna()\n",
    "urdu_doc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>میں نے اسے 80 کی دہائی کے وسط میں ایک کیبل گائ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>چونکہ میں نے 80 کی دہائی میں انسپکٹر گیجٹ کارٹ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ایک ایسے معاشرے کی حالت کے بارے میں تعجب کرتا ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>مفید البرٹ پیون کی طرف سے ایک اور ردی کی ٹوکری...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>یہ کولمبو ہے جس کی ہدایتکاری اپنے کیریئر کے اب...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  میں نے اسے 80 کی دہائی کے وسط میں ایک کیبل گائ...          1\n",
       "1  چونکہ میں نے 80 کی دہائی میں انسپکٹر گیجٹ کارٹ...          0\n",
       "2  ایک ایسے معاشرے کی حالت کے بارے میں تعجب کرتا ...          1\n",
       "3  مفید البرٹ پیون کی طرف سے ایک اور ردی کی ٹوکری...          0\n",
       "4  یہ کولمبو ہے جس کی ہدایتکاری اپنے کیریئر کے اب...          1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urdu_doc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    25000\n",
       "0    25000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urdu_doc['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the labels\n",
    "df = urdu_doc\n",
    "le = LabelEncoder()\n",
    "le.fit(df['sentiment'])\n",
    "df['encoded_sentiments'] = le.transform(df['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removing_unwanted_data(text):\n",
    "    \n",
    "    #format words and remove unwanted characters\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\<a href', ' ',text)\n",
    "    text = re.sub(r'&amp;', '', text)\n",
    "    text = re.sub(r'[_\"\\-;()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n",
    "    text = re.sub(r'<br />', ' ', text)\n",
    "    text = re.sub(r'\\'', ' ', text)\n",
    "    text = re.sub(r\"[:؛؟’‘٭ء،۔]+\", \" \", text)\n",
    "    text = re.sub(r\"[٠‎١‎٢‎٣‎٤‎٥‎٦‎٧‎٨‎٩]+\", \" \", text)\n",
    "    text = re.sub(r\"[a-zA-z0-9]+\", \" \", text)\n",
    "    \n",
    "    text = nltk.WordPunctTokenizer().tokenize(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "urdu_doc['text_cleaned']= list(map(removing_unwanted_data,urdu_doc.review)) #map -> name and data send in func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>encoded_sentiments</th>\n",
       "      <th>text_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>میں نے اسے 80 کی دہائی کے وسط میں ایک کیبل گائ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[میں, نے, اسے, کی, دہائی, کے, وسط, میں, ایک, ک...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>چونکہ میں نے 80 کی دہائی میں انسپکٹر گیجٹ کارٹ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[چونکہ, میں, نے, کی, دہائی, میں, انسپکٹر, گیجٹ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ایک ایسے معاشرے کی حالت کے بارے میں تعجب کرتا ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ایک, ایسے, معاشرے, کی, حالت, کے, بارے, میں, ت...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>مفید البرٹ پیون کی طرف سے ایک اور ردی کی ٹوکری...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[مفید, البرٹ, پیون, کی, طرف, سے, ایک, اور, ردی...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>یہ کولمبو ہے جس کی ہدایتکاری اپنے کیریئر کے اب...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[یہ, کولمبو, ہے, جس, کی, ہدایتکاری, اپنے, کیری...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment  \\\n",
       "0  میں نے اسے 80 کی دہائی کے وسط میں ایک کیبل گائ...          1   \n",
       "1  چونکہ میں نے 80 کی دہائی میں انسپکٹر گیجٹ کارٹ...          0   \n",
       "2  ایک ایسے معاشرے کی حالت کے بارے میں تعجب کرتا ...          1   \n",
       "3  مفید البرٹ پیون کی طرف سے ایک اور ردی کی ٹوکری...          0   \n",
       "4  یہ کولمبو ہے جس کی ہدایتکاری اپنے کیریئر کے اب...          1   \n",
       "\n",
       "   encoded_sentiments                                       text_cleaned  \n",
       "0                   1  [میں, نے, اسے, کی, دہائی, کے, وسط, میں, ایک, ک...  \n",
       "1                   0  [چونکہ, میں, نے, کی, دہائی, میں, انسپکٹر, گیجٹ...  \n",
       "2                   1  [ایک, ایسے, معاشرے, کی, حالت, کے, بارے, میں, ت...  \n",
       "3                   0  [مفید, البرٹ, پیون, کی, طرف, سے, ایک, اور, ردی...  \n",
       "4                   1  [یہ, کولمبو, ہے, جس, کی, ہدایتکاری, اپنے, کیری...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urdu_doc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop words from text\n",
    "from typing import FrozenSet\n",
    "\n",
    "# Urdu Language Stop words list\n",
    "STOP_WORDS: FrozenSet[str] = frozenset(\"\"\"\n",
    " آ آئی آئیں آئے آتا آتی آتے آس آمدید آنا آنسہ آنی آنے آپ آگے آہ آہا آیا اب ابھی ابے\n",
    " ارے اس اسکا اسکی اسکے اسی اسے اف افوہ البتہ الف ان اندر انکا انکی انکے انہوں انہی انہیں اوئے اور اوپر\n",
    " اوہو اپ اپنا اپنوں اپنی اپنے اپنےآپ اکثر اگر اگرچہ اہاہا ایسا ایسی ایسے ایک بائیں بار بارے بالکل باوجود باہر\n",
    " بج بجے بخیر بشرطیکہ بعد بعض بغیر بلکہ بن بنا بناؤ بند بڑی بھر بھریں بھی بہت بہتر تاکہ تاہم تب تجھ\n",
    " تجھی تجھے ترا تری تلک تم تمام تمہارا تمہاروں تمہاری تمہارے تمہیں تو تک تھا تھی تھیں تھے تیرا تیری تیرے\n",
    " جا جاؤ جائیں جائے جاتا جاتی جاتے جانی جانے جب جبکہ جدھر جس جسے جن جناب جنہوں جنہیں جو جہاں جی جیسا\n",
    " جیسوں جیسی جیسے حالانکہ حالاں حصہ حضرت خاطر خالی خواہ خوب خود دائیں درمیان دریں دو دوران دوسرا دوسروں دوسری دوں\n",
    " دکھائیں دی دیئے دیا دیتا دیتی دیتے دیر دینا دینی دینے دیکھو دیں دیے دے ذریعے رکھا رکھتا رکھتی رکھتے رکھنا رکھنی\n",
    " رکھنے رکھو رکھی رکھے رہ رہا رہتا رہتی رہتے رہنا رہنی رہنے رہو رہی رہیں رہے ساتھ سامنے ساڑھے سب سبھی\n",
    " سراسر سمیت سوا سوائے سکا سکتا سکتے سہ سہی سی سے شاید شکریہ صاحب صاحبہ صرف ضرور طرح طرف طور علاوہ عین\n",
    " فقط فلاں فی قبل قطا لئے لائی لائے لاتا لاتی لاتے لانا لانی لانے لایا لو لوجی لوگوں لگ لگا لگتا\n",
    " لگتی لگی لگیں لگے لہذا لی لیا لیتا لیتی لیتے لیکن لیں لیے لے ماسوا مت مجھ مجھی مجھے محترم محترمہ محض\n",
    " مرا مرحبا مری مرے مزید مس مسز مسٹر مطابق مل مکرمی مگر مگھر مہربانی میرا میروں میری میرے میں نا نزدیک\n",
    " نما نہ نہیں نیز نیچے نے و وار واسطے واقعی والا والوں والی والے واہ وجہ ورنہ وغیرہ ولے وگرنہ وہ وہاں\n",
    " وہی وہیں ویسا ویسے ویں پاس پایا پر پس پلیز پون پونی پونے پھر پہ پہلا پہلی پہلے پیر پیچھے چاہئے\n",
    " چاہتے چاہیئے چاہے چلا چلو چلیں چلے چناچہ چند چونکہ چکی چکیں چکے ڈالنا ڈالنی ڈالنے ڈالے کئے کا کاش کب کبھی\n",
    " کدھر کر کرتا کرتی کرتے کرم کرنا کرنے کرو کریں کرے کس کسی کسے کم کن کنہیں کو کوئی کون کونسا\n",
    " کونسے کچھ کہ کہا کہاں کہہ کہی کہیں کہے کی کیا کیسا کیسے کیونکر کیونکہ کیوں کیے کے گئی گئے گا گنا\n",
    " گو گویا گی گیا ہائیں ہائے ہاں ہر ہرچند ہرگز ہم ہمارا ہماری ہمارے ہمی ہمیں ہو ہوئی ہوئیں ہوئے ہوا\n",
    " ہوبہو ہوتا ہوتی ہوتیں ہوتے ہونا ہونگے ہونی ہونے ہوں ہی ہیلو ہیں ہے یا یات یعنی یک یہ یہاں یہی یہیں\n",
    "\"\"\".split())\n",
    "\n",
    "\n",
    "def remove_stopwords(text: str):\n",
    "    return \" \".join(word for word in text.split() if word not in STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urduhack.models.lemmatizer import lemmatizer\n",
    "def lemitizeStr(str):\n",
    "    lemme_str = \" \"\n",
    "    temp = lemmatizer.lemma_lookup(str)\n",
    "    for t in temp:\n",
    "        lemme_str += t[0] + \" \"\n",
    "    \n",
    "    return lemme_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] =  df['review'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lemmatized_text'] = df['review'].apply(lemitizeStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>encoded_sentiments</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>lemmatized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>80 دہائی وسط کیبل گائیڈ (اسکائینجر ہنٹ پہلو اپ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[میں, نے, اسے, کی, دہائی, کے, وسط, میں, ایک, ک...</td>\n",
       "      <td>80 دہائی وسط کیبل گائیڈ (اسکائینجر ہنٹ پہلو ا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>80 دہائی انسپکٹر گیجٹ کارٹون پسند ، فلم دیکھنے...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[چونکہ, میں, نے, کی, دہائی, میں, انسپکٹر, گیجٹ...</td>\n",
       "      <td>80 دہائی انسپکٹر گیجٹ کارٹون پسند ، فلم دیکھن...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>معاشرے حالت تعجب والد پیدا البرٹ ٹی فٹزجیرالڈ ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ایک, ایسے, معاشرے, کی, حالت, کے, بارے, میں, ت...</td>\n",
       "      <td>معاشرے حالت تعجب والد پیدا البرٹ ٹی فٹزجیرالڈ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>مفید البرٹ پیون ردی ٹوکری گریڈ زیڈ جلدی۔ ٹم تھ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[مفید, البرٹ, پیون, کی, طرف, سے, ایک, اور, ردی...</td>\n",
       "      <td>مفید البرٹ پیون ردی ٹوکری گریڈ زیڈ جلدی۔ ٹم ت...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>کولمبو ہدایتکاری کیریئر ابتدائی وقت اسٹیون اسپ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[یہ, کولمبو, ہے, جس, کی, ہدایتکاری, اپنے, کیری...</td>\n",
       "      <td>کولمبو ہدایتکاری کیریئر ابتدائی وقت اسٹیون اس...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment  \\\n",
       "0  80 دہائی وسط کیبل گائیڈ (اسکائینجر ہنٹ پہلو اپ...          1   \n",
       "1  80 دہائی انسپکٹر گیجٹ کارٹون پسند ، فلم دیکھنے...          0   \n",
       "2  معاشرے حالت تعجب والد پیدا البرٹ ٹی فٹزجیرالڈ ...          1   \n",
       "3  مفید البرٹ پیون ردی ٹوکری گریڈ زیڈ جلدی۔ ٹم تھ...          0   \n",
       "4  کولمبو ہدایتکاری کیریئر ابتدائی وقت اسٹیون اسپ...          1   \n",
       "\n",
       "   encoded_sentiments                                       text_cleaned  \\\n",
       "0                   1  [میں, نے, اسے, کی, دہائی, کے, وسط, میں, ایک, ک...   \n",
       "1                   0  [چونکہ, میں, نے, کی, دہائی, میں, انسپکٹر, گیجٹ...   \n",
       "2                   1  [ایک, ایسے, معاشرے, کی, حالت, کے, بارے, میں, ت...   \n",
       "3                   0  [مفید, البرٹ, پیون, کی, طرف, سے, ایک, اور, ردی...   \n",
       "4                   1  [یہ, کولمبو, ہے, جس, کی, ہدایتکاری, اپنے, کیری...   \n",
       "\n",
       "                                     lemmatized_text  \n",
       "0   80 دہائی وسط کیبل گائیڈ (اسکائینجر ہنٹ پہلو ا...  \n",
       "1   80 دہائی انسپکٹر گیجٹ کارٹون پسند ، فلم دیکھن...  \n",
       "2   معاشرے حالت تعجب والد پیدا البرٹ ٹی فٹزجیرالڈ...  \n",
       "3   مفید البرٹ پیون ردی ٹوکری گریڈ زیڈ جلدی۔ ٹم ت...  \n",
       "4   کولمبو ہدایتکاری کیریئر ابتدائی وقت اسٹیون اس...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urdu_doc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples per class: [25000 25000]\n"
     ]
    }
   ],
   "source": [
    "print(\"Samples per class: {}\".format(np.bincount(urdu_doc.encoded_sentiments)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(df['lemmatized_text'], df['encoded_sentiments'], test_size = 0.30, random_state = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train (35000,)\n",
      "Shape of X_test (15000,)\n",
      "Shape of Y_train (35000,)\n",
      "Shape of Y_test (15000,)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of X_train', X_train.shape)\n",
    "print('Shape of X_test', X_test.shape)\n",
    "print('Shape of Y_train', Y_train.shape)\n",
    "print('Shape of Y_test', Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of columns are = 303\n",
      "Shape of arrays = (50000, 303)\n"
     ]
    }
   ],
   "source": [
    "BOW_convert = CountVectorizer(tokenizer=lambda doc: doc, lowercase=False)\n",
    "x = BOW_convert.fit_transform(df['lemmatized_text'])\n",
    "\n",
    "words = BOW_convert.get_feature_names()\n",
    "print(\"The total number of columns are =\",len(words))\n",
    "print('Shape of arrays =',x.toarray().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data set shape = (35000, 5)\n",
      "Testing data set shape = (15000, 5)\n"
     ]
    }
   ],
   "source": [
    "import sklearn.model_selection\n",
    "\n",
    "train,test= sklearn.model_selection.train_test_split(df, train_size = 0.7, random_state=4) #Split and Shuffle\n",
    "\n",
    "print('Training data set shape =',train.shape)\n",
    "print('Testing data set shape =', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35000, 282)\n",
      "(35000,)\n",
      "(15000, 282)\n",
      "(15000,)\n"
     ]
    }
   ],
   "source": [
    "BOW_convert = CountVectorizer(tokenizer=lambda doc: doc, lowercase=False)\n",
    "\n",
    "X_train = BOW_convert.fit_transform(train['lemmatized_text'])\n",
    "\n",
    "X_test = BOW_convert.transform(test['lemmatized_text'])\n",
    "\n",
    "Y_train=train['encoded_sentiments']\n",
    "Y_test=test['encoded_sentiments']\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM MODEL BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_model= SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters = {\n",
    " 'C': [0.2], 'kernel': ['linear'],\n",
    " 'C': [0.2], 'gamma': [0.1], 'kernel': ['linear'],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "model_svm = RandomizedSearchCV(svm_model, tuned_parameters,cv=10,scoring='accuracy',n_iter=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svm.fit(X_train, Y_train)\n",
    "print(model_svm.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_svm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= model_svm.predict(X_test)\n",
    "print(metrics.accuracy_score(y_pred,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix=metrics.confusion_matrix(Y_test,y_pred)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_roc=metrics.classification_report(Y_test,y_pred)\n",
    "auc_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_roc=metrics.roc_auc_score(Y_test,y_pred)\n",
    "auc_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(Y_test, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(false_positive_rate,true_positive_rate, color='red',label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],linestyle='--')\n",
    "plt.axis('tight')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
